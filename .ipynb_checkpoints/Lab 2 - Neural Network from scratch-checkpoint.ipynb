{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks can be intimidating, especially for people new to machine learning. There are several Neural Network libraries in Python (ex. Keras & TensorFlow) abstracting complicated details and computations (ex. matrix multiplications and Gradiend Decent). However, for educational purposes, we will build our own NN from scratch using Numpy only. This will help us break down how exactly NN works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets build this NN:\n",
    "<img src=\"images/FeedForwardNeuralNetwork.png\" alt=\"jupyter_notebook\" title=\"jupyter_notebook\" height=\"520\" width=\"220\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42) # to reproduce same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation function\n",
    "The output of each artificial neuron is the sum of inputs times weights passed through an activation function. There are a lot of activation functions, each has its own pros & cons...\n",
    "<img src=\"images/activation_functions.png\" alt=\"activation_functions\" title=\"activation_functions\" height=\"220\" width=\"820\"/>\n",
    "Here, we will be using Sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define sigmoid and its derivative\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training data\n",
    "<img src=\"images/training_data.png\" alt=\"training_data\" title=\"training_data\" height=\"220\" width=\"420\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.  18.]\n",
      " [  6.  15.]\n",
      " [  8.  12.]\n",
      " [ 10.   8.]]\n",
      "[[ 89.]\n",
      " [ 84.]\n",
      " [ 79.]\n",
      " [ 72.]]\n"
     ]
    }
   ],
   "source": [
    "# X = (hours sleeping, hours studying), y = score on test\n",
    "x = np.array(([3, 18], [6, 15], [8, 12], [10,8]), dtype=float) # 4 X 2\n",
    "y = np.array(([89], [84], [79], [72]), dtype=float) # 4 X 1\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (scaling)\n",
    "Sometimes, the range of values of raw data varies widely. In that case, objective functions will not work properly without normalization. Normalizatoin also helps gradient descent to converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.125       0.75      ]\n",
      " [ 0.25        0.625     ]\n",
      " [ 0.33333333  0.5       ]\n",
      " [ 0.41666667  0.33333333]]\n",
      "[[ 0.89]\n",
      " [ 0.84]\n",
      " [ 0.79]\n",
      " [ 0.72]]\n"
     ]
    }
   ],
   "source": [
    "x /= 24\n",
    "y /= 100\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize learnable parameters: wweights and biases\n",
    "usually as small random values, but 0.5 here to compare with our manual solution. Ignore bias for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.ones((3,2)) * 0.5  # 3 X 2 --> 3 neurons, each has two inputs\n",
    "w2 = np.ones((1,3)) * 0.5 # 1 X 3 --> single neuron with three inputs\n",
    "print(w1)\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_output [[ 0.60766317  0.60766317  0.60766317]\n",
      " [ 0.60766317  0.60766317  0.60766317]\n",
      " [ 0.60268534  0.60268534  0.60268534]\n",
      " [ 0.5926666   0.5926666   0.5926666 ]]\n",
      "output [[ 0.71330594]\n",
      " [ 0.71330594]\n",
      " [ 0.71177656]\n",
      " [ 0.70868374]]\n",
      "delta [[ 0.03613404]\n",
      " [ 0.02590901]\n",
      " [ 0.01604759]\n",
      " [ 0.00233625]]\n",
      "gradient [[ 0.04875754  0.04875754  0.04875754]]\n",
      "delta2 [[ 0.00430733  0.00430733  0.00430733]\n",
      " [ 0.00308847  0.00308847  0.00308847]\n",
      " [ 0.00192134  0.00192134  0.00192134]\n",
      " [ 0.000282    0.000282    0.000282  ]]\n",
      "gradient2 [[ 0.00206848  0.00621546]\n",
      " [ 0.00206848  0.00621546]\n",
      " [ 0.00206848  0.00621546]]\n",
      "w1 [[ 0.51034241  0.53107732]\n",
      " [ 0.51034241  0.53107732]\n",
      " [ 0.51034241  0.53107732]]\n",
      "w2 [[ 0.74378771  0.74378771  0.74378771]]\n",
      "final output: [[ 0.88665845]\n",
      " [ 0.84066193]\n",
      " [ 0.79021833]\n",
      " [ 0.72247807]]\n"
     ]
    }
   ],
   "source": [
    "lr = 5 # learning rate\n",
    "epochs = np.arange(2000)\n",
    "sse = []\n",
    "\n",
    "for i in epochs:\n",
    "\n",
    "    # feed forward\n",
    "    hidden_output = sigmoid( np.matmul(x, w1.T) ) # 4 X 3\n",
    "    output = sigmoid( np.matmul(hidden_output, w2.T) ) # 4 X 1\n",
    "    \n",
    "    error = np.sum(0.5 * (y - output)**2)\n",
    "    sse.append(error)\n",
    "\n",
    "    # backpropagation\n",
    "\n",
    "    delta = (y-output) * sigmoid_prime(output) # 4 X 1\n",
    "    gradient = np.transpose(hidden_output.T.dot( delta )) # 1 X 3\n",
    "    #w2 += lr * gradient # adjusting second set (hidden --> output) weights\n",
    "\n",
    "    delta2 = delta.dot(w2) * sigmoid_prime(hidden_output) # 5 X 3\n",
    "    gradient2 = np.transpose(x.T.dot(delta2)) # 3 X 2\n",
    "    \n",
    "    w2 += lr * gradient # adjusting second set (hidden --> output) weights\n",
    "    w1 += lr * gradient2 # adjusting first set (input --> hidden) weights\n",
    "    \n",
    "    if i == 0:\n",
    "        print('hidden_output', hidden_output)\n",
    "        print('output', output)\n",
    "        print('delta', delta)\n",
    "        print('gradient', gradient)\n",
    "        print('delta2', delta2)\n",
    "        print('gradient2', gradient2)\n",
    "        print('w1', w1)\n",
    "        print('w2', w2)\n",
    "\n",
    "#print('w1:', w1, 'w2:', w2)\n",
    "print('final output:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nItIiChIREWkRBYmIiLTI/wfXhSjPKM8I1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x99345e04e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sse[1:])\n",
    "plt.ylabel('SSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2     y        h1        h2        h3     y_hat       sse  \\\n",
      "0  0.125000  0.750000  0.89  0.607663  0.607663  0.607663  0.713306  0.015610   \n",
      "1  0.250000  0.625000  0.84  0.607663  0.607663  0.607663  0.713306  0.008026   \n",
      "2  0.333333  0.500000  0.79  0.602685  0.602685  0.602685  0.711777  0.003059   \n",
      "3  0.416667  0.333333  0.72  0.592667  0.592667  0.592667  0.708684  0.000064   \n",
      "\n",
      "      delta  \n",
      "0  0.036134  \n",
      "1  0.025909  \n",
      "2  0.016048  \n",
      "3  0.002336  \n",
      "2.4106782776\n",
      "3.24\n",
      "2.84707217613\n",
      "0.0804268932773\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sse(x1,x2,w1,w2,y):\n",
    "    y_hat = w1*x1 + w2*x2\n",
    "    print(y_hat)\n",
    "    sse = 0.5 * (y - y_hat) **2\n",
    "    print(sse)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['x1'] = x[:,0]\n",
    "df['x2'] = x[:,1]\n",
    "df['y'] = y.flatten()\n",
    "df['h1'] = hidden_output[:,0]\n",
    "df['h2'] = hidden_output[:,1]\n",
    "df['h3'] = hidden_output[:,2]\n",
    "df['y_hat'] = output.flatten()\n",
    "df['sse'] = 0.5 * (df['y'] - df['y_hat']) **2\n",
    "df['delta'] = (df['y'] - df['y_hat']) * sigmoid_prime(df['y_hat']) # 4 X 1\n",
    "#df['Gw7'] = df['delta'] * df['h1']\n",
    "#df['Gw8'] = df['delta'] * df['h2']\n",
    "#df['Gw9'] = df['delta'] * df['h3']\n",
    "print(df)\n",
    "print(df['h1'].sum())\n",
    "print(df['y'].sum())\n",
    "print(df['y_hat'].sum())\n",
    "print(df['delta'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00525310854144 0.00525310854144 0.00525310854144\n",
      "0.00357471230143 0.00357471230143 0.00357471230143\n",
      "0.00210716972117 0.00210716972117 0.00210716972117\n",
      "0.000285905501693 0.000285905501693 0.000285905501693\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours sleeping</th>\n",
       "      <th>hours studing</th>\n",
       "      <th>final grade</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>y_hat</th>\n",
       "      <th>SSE</th>\n",
       "      <th>delta</th>\n",
       "      <th>gradient 7</th>\n",
       "      <th>gradient 8</th>\n",
       "      <th>gradient 9</th>\n",
       "      <th>gradient 1</th>\n",
       "      <th>gradient 2</th>\n",
       "      <th>gradient 3</th>\n",
       "      <th>gradient 4</th>\n",
       "      <th>gradient 5</th>\n",
       "      <th>gradient 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.713306</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.036134</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.003940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.713306</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.025909</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.602685</td>\n",
       "      <td>0.602685</td>\n",
       "      <td>0.602685</td>\n",
       "      <td>0.711777</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.016048</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hours sleeping  hours studing  final grade        h1        h2        h3  \\\n",
       "0        0.125000       0.750000         0.89  0.607663  0.607663  0.607663   \n",
       "1        0.250000       0.625000         0.84  0.607663  0.607663  0.607663   \n",
       "2        0.333333       0.500000         0.79  0.602685  0.602685  0.602685   \n",
       "3        0.416667       0.333333         0.72  0.592667  0.592667  0.592667   \n",
       "\n",
       "      y_hat       SSE     delta  gradient 7  gradient 8  gradient 9  \\\n",
       "0  0.713306  0.015610  0.036134    0.021957    0.021957    0.021957   \n",
       "1  0.713306  0.008026  0.025909    0.015744    0.015744    0.015744   \n",
       "2  0.711777  0.003059  0.016048    0.009672    0.009672    0.009672   \n",
       "3  0.708684  0.000064  0.002336    0.001385    0.001385    0.001385   \n",
       "\n",
       "   gradient 1  gradient 2  gradient 3  gradient 4  gradient 5  gradient 6  \n",
       "0    0.000657    0.003940    0.000657    0.003940    0.000657    0.003940  \n",
       "1    0.000894    0.002234    0.000894    0.002234    0.000894    0.002234  \n",
       "2    0.000702    0.001054    0.000702    0.001054    0.000702    0.001054  \n",
       "3    0.000119    0.000095    0.000119    0.000095    0.000119    0.000095  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x = np.array(([3, 18], [6, 15], [8, 12], [10,8]), dtype=float) # 4 X 2\n",
    "y = np.array(([89], [84], [79], [72]), dtype=float) # 4 X 1\n",
    "\n",
    "x /= 24\n",
    "y /= 100\n",
    "\n",
    "w1 = np.ones((3,2)) * 0.5  # 3 X 2 --> 3 neurons, each has two inputs\n",
    "w2 = np.ones((1,3)) * 0.5 # 1 X 3 --> single neuron with three inputs\n",
    "\n",
    "h1s, h2s, h3s, y_hats, y_y_hats, sses, deltas, G7s, G8s, G9s = [], [], [], [], [], [], [], [], [], []\n",
    "G1s, G2s, G3s, G4s, G5s, G6s = [], [], [], [], [], []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # ff\n",
    "    h1 = sigmoid( x[i,0] * w1[0,0] + x[i,1] * w1[0,1] )\n",
    "    h1s.append(h1)\n",
    "    h2 = sigmoid( x[i,0] * w1[1,0] + x[i,1] * w1[1,1] )\n",
    "    h2s.append(h2)\n",
    "    h3 = sigmoid( x[i,0] * w1[2,0] + x[i,1] * w1[2,1] )\n",
    "    h3s.append(h3)\n",
    "    y_hat = sigmoid( h1 * w2[0,0] + h2 * w2[0,1] + h1 * w2[0,2] )\n",
    "    y_hats.append(y_hat)\n",
    "    sse = 0.5 * (y[i,0] - y_hat)**2\n",
    "    sses.append(sse)\n",
    "    y_y_hats.append(y[i,0] - y_hat)\n",
    "    # Bp\n",
    "    delta = (y[i,0] - y_hat) * y_hat * (1 - y_hat)\n",
    "    deltas.append(delta)\n",
    "    G7 = delta * h1\n",
    "    G8 = delta * h2\n",
    "    G9 = delta * h3\n",
    "    G7s.append(G7)\n",
    "    G8s.append(G8)\n",
    "    G9s.append(G9)\n",
    "    \n",
    "    ####  update w2 || calculate Gradiends 1 to 9.. whuch is first ???\n",
    "    \n",
    "    #update weights\n",
    "#     w2_new1 = w2[0,0] + 5*G7\n",
    "#     w2_new2 = w2[0,1] + 5*G8\n",
    "#     w2_new3 = w2[0,2] + 5*G9\n",
    "    \n",
    "    delta2 = delta * h1 * (1-h1) * w2_new1\n",
    "    delta3 = delta * h2 * (1-h2) * w2_new2\n",
    "    delta4 = delta * h3 * (1-h3) * w2_new3\n",
    "    print(delta2, delta3, delta4)\n",
    "    G1 = delta2 * x[i,0]\n",
    "    G2 = delta2 * x[i,1]\n",
    "    G3 = delta3 * x[i,0]\n",
    "    G4 = delta3 * x[i,1]\n",
    "    G5 = delta4 * x[i,0]\n",
    "    G6 = delta4 * x[i,1]\n",
    "    G1s.append(G1)\n",
    "    G2s.append(G2)\n",
    "    G3s.append(G3)\n",
    "    G4s.append(G4)\n",
    "    G5s.append(G5)\n",
    "    G6s.append(G6)\n",
    "    \n",
    "\n",
    "df['hours sleeping'] = x[:,0]\n",
    "df['hours studing'] = x[:,1]\n",
    "df['final grade'] = y[:,0]\n",
    "df['h1'] = h1s\n",
    "df['h2'] = h2s\n",
    "df['h3'] = h3s\n",
    "df['y_hat'] = y_hats\n",
    "df['SSE'] = sses\n",
    "df['delta'] = deltas\n",
    "df['gradient 7'] = G7s\n",
    "df['gradient 8'] = G8s\n",
    "df['gradient 9'] = G9s\n",
    "\n",
    "df['gradient 1'] = G1s\n",
    "df['gradient 2'] = G2s\n",
    "df['gradient 3'] = G3s\n",
    "df['gradient 4'] = G4s\n",
    "df['gradient 5'] = G5s\n",
    "df['gradient 6'] = G6s\n",
    "\n",
    "df.head()\n",
    "\n",
    "#print(sum(h1s), sum(h2s), sum(h3s), sum(y_hats), sum(y_y_hats), sum(sses), sum(deltas), sum(G7s), sum(G8s), sum(G9s))\n",
    "#print(h1, h2, h3, y_hat)\n",
    "\n",
    "# Bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('backpropagation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002371833842465075"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gradient 1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.531075"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5+5*0.006215"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
